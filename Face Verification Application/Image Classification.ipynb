{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as FR\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectFace(Filename, Size=((160, 160))):\n",
    "\n",
    "    UserImage = cv2.imread(Filename)\n",
    "    UserImage = cv2.cvtColor(UserImage, cv2.COLOR_BGR2RGB)\n",
    "    ImageArray = np.array(UserImage)\n",
    "    FaceDetails = mtcnn.detect_faces(ImageArray)\n",
    "    try:\n",
    "        x, y, width, height = FaceDetails[0][\"box\"]\n",
    "        x1, y1, x2, y2 = abs(x), abs(y), x + width, y + height\n",
    "        FacePoints = ImageArray[y1:y2, x1:x2]\n",
    "        CroppedFace = Image.fromarray(FacePoints)\n",
    "        CroppedFace = CroppedFace.resize(Size)\n",
    "        FaceArray = np.array(CroppedFace)\n",
    "        print(\"loded file:\",Filename)\n",
    "    except:\n",
    "        FaceArray = []\n",
    "        print(\"Could not detect face for:\", Filename)\n",
    "    return FaceArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loded file: D:/Deep Learning/100Images/SaiKrishna/IMG_20210207_141042_1.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[102, 100, 103],\n",
       "        [106, 104, 107],\n",
       "        [ 68,  66,  69],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[ 90,  88,  90],\n",
       "        [ 88,  86,  89],\n",
       "        [102, 100, 102],\n",
       "        ...,\n",
       "        [255, 255, 253],\n",
       "        [253, 250, 236],\n",
       "        [254, 253, 245]],\n",
       "\n",
       "       [[ 69,  66,  69],\n",
       "        [ 58,  56,  59],\n",
       "        [ 25,  23,  25],\n",
       "        ...,\n",
       "        [255, 255, 252],\n",
       "        [252, 242, 219],\n",
       "        [245, 233, 207]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[194, 195, 186],\n",
       "        [202, 202, 192],\n",
       "        [193, 192, 181],\n",
       "        ...,\n",
       "        [ 22,  23,  29],\n",
       "        [ 22,  26,  32],\n",
       "        [ 22,  25,  30]],\n",
       "\n",
       "       [[231, 231, 220],\n",
       "        [212, 211, 199],\n",
       "        [201, 199, 187],\n",
       "        ...,\n",
       "        [ 24,  25,  30],\n",
       "        [ 22,  26,  32],\n",
       "        [ 22,  26,  34]],\n",
       "\n",
       "       [[229, 227, 215],\n",
       "        [203, 201, 188],\n",
       "        [203, 200, 187],\n",
       "        ...,\n",
       "        [ 25,  27,  32],\n",
       "        [ 21,  26,  32],\n",
       "        [ 22,  26,  37]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectFace(\"D:/Deep Learning/100Images/SaiKrishna/IMG_20210207_141042_1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetectFace(Filename, Size=((160, 160))):\n",
    "\n",
    "    UserImage = cv2.imread(Filename)\n",
    "    UserImage = cv2.cvtColor(UserImage, cv2.COLOR_BGR2RGB)\n",
    "    ImageArray = np.array(UserImage)\n",
    "    \n",
    "    FaceDetails = FR.face_locations(ImageArray)\n",
    "    if FaceDetails != []:\n",
    "        top, right, bottom, left = FaceDetails[0]\n",
    "        FaceImage = UserImage[top:bottom, left:right]\n",
    "        CroppedFace = Image.fromarray(FaceImage)\n",
    "        CroppedFace = CroppedFace.resize(Size)\n",
    "        FaceArray = np.array(CroppedFace)\n",
    "        print(\"loded file:\",Filename)\n",
    "    else:\n",
    "        FaceArray = []\n",
    "        print(\"Could not detect face for:\", Filename)\n",
    "    return FaceArray\n",
    "\n",
    "def DetectFaceold(Filename, Size=((160, 160))):\n",
    "\n",
    "    UserImage = cv2.imread(Filename)\n",
    "    UserImage = cv2.cvtColor(UserImage, cv2.COLOR_BGR2RGB)\n",
    "    ImageArray = np.array(UserImage)\n",
    "    FaceDetails = mtcnn.detect_faces(ImageArray)\n",
    "    try:\n",
    "        x, y, width, height = FaceDetails[0][\"box\"]\n",
    "        x1, y1, x2, y2 = abs(x), abs(y), x + width, y + height\n",
    "        FacePoints = ImageArray[y1:y2, x1:x2]\n",
    "        CroppedFace = Image.fromarray(FacePoints)\n",
    "        CroppedFace = CroppedFace.resize(Size)\n",
    "        FaceArray = np.array(CroppedFace)\n",
    "        print(\"loded file:\",Filename)\n",
    "    except:\n",
    "        FaceArray = []\n",
    "        print(\"Could not detect face for:\", Filename)\n",
    "    return FaceArray\n",
    "\n",
    "\n",
    "def LoadDataset(Directory):\n",
    "    x, y = [], []\n",
    "    for subdir in listdir(Directory):\n",
    "\n",
    "        path = Directory + subdir + \"/\"\n",
    "\n",
    "        AllFacesArray = []\n",
    "        for File in listdir(path):\n",
    "            FaceArray = DetectFace(path + File)\n",
    "            if FaceArray != []:\n",
    "                AllFacesArray.append(FaceArray)\n",
    "\n",
    "        x.extend(AllFacesArray)\n",
    "        Labels = [subdir for _ in range(len(AllFacesArray))]\n",
    "        y.extend(Labels)\n",
    "        # print(Labels)\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "def GetFaceEmbeddings(FacePixels):\n",
    "#     FacePixels = FacePixels.astype(\"float32\")\n",
    "#     Mean, Std = FacePixels.mean(), FacePixels.std()\n",
    "#     FacePixels = (FacePixels - Mean) / Std\n",
    "#     FacePixels = expand_dims(FacePixels, axis=0)\n",
    "    print(FacePixels.shape)\n",
    "    Yhat = FR.face_encodings(FacePixels)\n",
    "#     print(Yhat[0].shape)\n",
    "    return Yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loading Initiated!\n",
      "Could not detect face for: D:/Deep Learning/test/Sai/IMG-20190730-WA0006_1.jpg\n",
      "loded file: D:/Deep Learning/test/Sai/IMG-20190730-WA0006_2.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\anaconda3\\envs\\DeepLearningProject\\lib\\site-packages\\ipykernel_launcher.py:49: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loded file: D:/Deep Learning/test/Sai/IMG-20190730-WA0006_3.jpg\n",
      "Could not detect face for: D:/Deep Learning/test/Sai/IMG-20190730-WA0006_4.jpg\n",
      "loded file: D:/Deep Learning/test/Sai/IMG-20190730-WA0006_5.jpg\n",
      "loded file: D:/Deep Learning/test/San/4a4c364a-a068-11ed-a2d1-001a7dda7115_0.jpg\n",
      "Could not detect face for: D:/Deep Learning/test/San/4a4c364a-a068-11ed-a2d1-001a7dda7115_1.jpg\n",
      "Could not detect face for: D:/Deep Learning/test/San/4a4c364a-a068-11ed-a2d1-001a7dda7115_3.jpg\n",
      "Data has been Loaded!\n"
     ]
    }
   ],
   "source": [
    "print(\"Data Loading Initiated!\")\n",
    "TrainData = LoadDataset(\"D:/Deep Learning/test/\")\n",
    "print(\"Data has been Loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 160, 3)\n",
      "[]\n",
      "(160, 160, 3)\n",
      "[array([-0.15752795,  0.0905816 , -0.01980995, -0.05631921, -0.06350461,\n",
      "       -0.0782681 ,  0.0183919 , -0.01247584,  0.17145865, -0.00701879,\n",
      "        0.21160585,  0.03812008, -0.29242513, -0.11691378, -0.05105925,\n",
      "        0.06876374, -0.17321402, -0.13194069, -0.02430442, -0.05413655,\n",
      "        0.09031276,  0.0769575 ,  0.05802556,  0.03567544, -0.13737632,\n",
      "       -0.27769968, -0.04764588, -0.13684319,  0.0872132 , -0.1351037 ,\n",
      "        0.06283382,  0.09186446, -0.17122217, -0.05564869,  0.01766398,\n",
      "        0.1172729 ,  0.08602773, -0.00171946,  0.22981434,  0.00233306,\n",
      "       -0.15032047, -0.09556532,  0.00746203,  0.26604947,  0.04847831,\n",
      "        0.00749725,  0.03907477, -0.03826442,  0.02948655, -0.1986791 ,\n",
      "        0.09693639,  0.13936856,  0.08594744, -0.00486665,  0.07701544,\n",
      "       -0.22958387,  0.00494477,  0.09775631, -0.22375247,  0.09358767,\n",
      "        0.00707053, -0.05123783, -0.09951509, -0.00823902,  0.20351425,\n",
      "        0.07892305, -0.10055663, -0.16716723,  0.23115046, -0.14438023,\n",
      "       -0.0673977 ,  0.13389082, -0.05966141, -0.11236857, -0.21545595,\n",
      "        0.03484029,  0.35038894,  0.09498193, -0.1790251 ,  0.122968  ,\n",
      "       -0.07503732, -0.0654071 ,  0.02662782,  0.07394597, -0.11315918,\n",
      "        0.13013761, -0.1511389 ,  0.04707679,  0.09524207,  0.05676857,\n",
      "       -0.07925848,  0.18593141,  0.00898095,  0.08036494,  0.12071589,\n",
      "        0.02674136, -0.05899955, -0.02628784, -0.08260094, -0.03703039,\n",
      "        0.18498787, -0.14692895, -0.03428112,  0.10849778, -0.08446278,\n",
      "        0.07510018, -0.01152585, -0.01587445, -0.01963333,  0.05465317,\n",
      "       -0.0564224 , -0.03510494,  0.15124257, -0.26914012,  0.27670765,\n",
      "        0.117296  , -0.05558424,  0.15135717,  0.0753205 ,  0.09130193,\n",
      "        0.03855191, -0.0462029 , -0.14523995, -0.11148814,  0.02626493,\n",
      "       -0.06999008,  0.09521636,  0.04330073])]\n",
      "here\n",
      "(160, 160, 3)\n",
      "[]\n",
      "(160, 160, 3)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = TrainData\n",
    "new_train_x, new__train_y = [], []\n",
    "for x_pixels,y_pixels in zip(x_train,y_train):\n",
    "    \n",
    "    embedding = GetFaceEmbeddings(x_pixels)\n",
    "    print(embedding)\n",
    "    if embedding != []:\n",
    "        print(\"here\")\n",
    "        new_train_x.append(embedding)\n",
    "        new__train_y.append(y_pixels)\n",
    "new_train_x = np.array(new_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d79b70235208>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mInEncoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mnew_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInEncoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "XTrain, YTrain = new_train_x, new__train_y\n",
    "print(XTrain.shape)\n",
    "InEncoder = Normalizer(norm=\"l2\")\n",
    "new_embedding = InEncoder.transform(embedding.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = RandomizedPCA(n_components=150, whiten=True, random_state=42)\n",
    "svc = SVC(kernel='rbf', class_weight='balanced')\n",
    "model = make_pipeline(pca, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(XTrain, YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Accuracy: ',model.score(XTrain,YTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(116, 287, 270, 132)]\n"
     ]
    }
   ],
   "source": [
    "Filename = \"D:/Deep Learning/Face Verification Training Data/SantoshGopane/Capture4_0.jpg\"\n",
    "UserImage = cv2.imread(Filename)\n",
    "UserImage = cv2.cvtColor(UserImage, cv2.COLOR_BGR2RGB)\n",
    "ImageArray = np.array(UserImage)\n",
    "\n",
    "FaceDetails = FR.face_locations(ImageArray)\n",
    "print(FaceDetails)\n",
    "\n",
    "top, right, bottom, left = FaceDetails[0]\n",
    "face_image = UserImage[top:bottom, left:right]\n",
    "# cv2.imshow(\"show\",face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.14230253,  0.13182449, -0.035429  , -0.01483868, -0.05949162,\n",
       "       -0.00997052,  0.00385974, -0.09793419,  0.1779612 , -0.01478299,\n",
       "        0.17214133, -0.01124156, -0.25326833, -0.03900156, -0.06240363,\n",
       "        0.02984867, -0.13372651, -0.2120291 , -0.03148786, -0.06390009,\n",
       "        0.02893915,  0.0227257 , -0.10884596,  0.07440409, -0.23013617,\n",
       "       -0.24712673, -0.07961179, -0.16410612,  0.00538145, -0.09250364,\n",
       "        0.01985536, -0.01655311, -0.24631654, -0.05280923,  0.00185228,\n",
       "        0.0548199 ,  0.04464499,  0.00795025,  0.17335756,  0.01751709,\n",
       "       -0.10140628, -0.03616961,  0.05796118,  0.29789108,  0.06329816,\n",
       "        0.03633055,  0.02780062,  0.00052108,  0.02952176, -0.23390648,\n",
       "        0.02648886,  0.15578236,  0.17754868,  0.04395687,  0.0057524 ,\n",
       "       -0.21846364, -0.00117568,  0.03728198, -0.2145846 ,  0.13001889,\n",
       "        0.05943723, -0.0279469 , -0.0877282 ,  0.01447411,  0.29279605,\n",
       "        0.09672185, -0.10634211, -0.11675663,  0.17356344, -0.20695822,\n",
       "       -0.03715203,  0.0671427 , -0.04047814, -0.16653216, -0.25443828,\n",
       "        0.06980526,  0.44323769,  0.16368772, -0.17880446,  0.08663593,\n",
       "       -0.16699402,  0.01611107,  0.02690121, -0.06145531, -0.13192311,\n",
       "        0.0858985 , -0.15262115,  0.07625368,  0.24831188,  0.06380487,\n",
       "       -0.0292425 ,  0.13828355,  0.00265709,  0.0257141 ,  0.05194513,\n",
       "       -0.00673161, -0.06611945, -0.07149193, -0.01864273,  0.03462138,\n",
       "        0.05360216, -0.06242149,  0.02091039,  0.13370602, -0.16441092,\n",
       "        0.11251245,  0.01867994, -0.07013949, -0.07103401,  0.11114109,\n",
       "       -0.121942  , -0.04422723,  0.17556015, -0.30231905,  0.21491627,\n",
       "        0.09130576, -0.03914775,  0.13123667,  0.03081408,  0.02883288,\n",
       "       -0.0348848 ,  0.00274056, -0.14809938, -0.14350489,  0.01827455,\n",
       "       -0.10901953,  0.13280012,  0.03565067])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat = FR.face_encodings(face_image)\n",
    "Yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
